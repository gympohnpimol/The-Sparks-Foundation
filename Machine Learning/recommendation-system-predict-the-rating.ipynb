{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pip install surprise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nimport seaborn as sns\nimport os\nimport random\nimport matplotlib.pyplot as plt\n\nfrom scipy import sparse\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics import mean_squared_error\n\nimport xgboost as xgb\nfrom surprise import Reader, Dataset, BaselineOnly, KNNBaseline, SVD, SVDpp\nfrom surprise.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n## coiuld replace with pd.read_csv and dropping NaNs/ : cols ? \n\n# DataFrame to store all imported data\nif not os.path.isfile('data.cs'):\n    data = open('data.csv', mode='w')\n\nfiles = ['../input/netflix-prize-data/combined_data_1.txt',\n         '../input/netflix-prize-data/combined_data_2.txt',\n#          '../input/netflix-prize-data/combined_data_3.txt',  # read in half of data only for speedup\n#          '../input/netflix-prize-data/combined_data_4.txt'\n        ]\n\n# Remove the line with movie_id: and add a new column of movie_id\n# Combine all data files into a csv file\nfor file in files:\n  print(\"Opening file: {}\".format(file))\n  with open(file) as f:\n    for line in f:\n        line = line.strip()\n        if line.endswith(':'):\n            movie_id = line.replace(':', '')\n        else:\n            data.write(movie_id + ',' + line)\n            data.write('\\n')\ndata.close()\n\n# Read all data into a pd dataframe\ndf = pd.read_csv('data.csv', names=['movie_id', 'user_id','rating','date'])\nprint(df.nunique())\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()[\"rating\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Removing the duplicated row"},{"metadata":{"trusted":true},"cell_type":"code","source":"duplication = df.duplicated([\"movie_id\", \"user_id\", \"rating\"])\nprint(\"Number of duplication rows: \"+str(duplication.sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total number of movie ratings: \"+str(sum(df[\"rating\"])))\nprint(\"Total number of users: \"+str(len(np.unique(df[\"user_id\"]))))\nprint(\"Total number of movies: \" +str(len(np.unique(df[\"movie_id\"]))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratary Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def labels(number):\n    return str(number/10**6) + \"M\"\n\nplt.figure(figsize=(12,8))\nax = sns.countplot(x=\"rating\", data= df)\nax.set_yticklabels([labels(num) for num in ax.get_yticks()])\n\nplt.tick_params(labelsize=15)\nplt.title(\"Rating Distribution\", fontsize=20)\nplt.xlabel(\"Rating\", fontsize=20)\nplt.ylabel(\"Number of Rating(Millions)\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"date\"] = pd.to_datetime(df[\"date\"], errors='coerce')\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = df.resample(\"M\", on = \"date\")[\"rating\"].count().plot()\n\nax.set_yticklabels([labels(num) for num in ax.get_yticks()])\nax.set_title(\"Rating per Month\", fontsize=20)\nax.set_xlabel(\"date\", fontsize=20)\nax.set_ylabel(\"Rating per Month(millions)\", fontsize=20)\nplt.tick_params(labelsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Rating Analyst by Giving User "},{"metadata":{"trusted":true},"cell_type":"code","source":"user_giving_rate = df.groupby(\"user_id\")[\"rating\"].count().sort_values(ascending=False)\nuser_giving_rate.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figs, axes = plt.subplots(nrows=1, ncols=2, figsize=(14,7))\n\nsns.kdeplot(user_giving_rate.values, shade=True, ax=axes[0])\naxes[0].set_title(\"PDF\", fontsize=20)\naxes[0].set_xlabel(\"Rating by User\", fontsize=15)\naxes[0].tick_params(labelsize=15)\n\nsns.kdeplot(user_giving_rate.values, shade=True, cumulative=True, ax=axes[1])\naxes[1].set_title(\"CDF\", fontsize=20)\naxes[1].set_xlabel(\"Rating by User\", fontsize=15)\naxes[1].tick_params(labelsize=15)\n\nfigs.subplots_adjust(wspace=2)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_giving_rate.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quantiles = user_giving_rate.quantile(np.arange(0, 1.01, 0.01 ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\naxes = fig.add_axes([0.1, 0.1, 1, 1])\naxes.set_title(\"Quantile of Rating/User\", fontsize=20)\naxes.set_xlabel(\"Quantile\", fontsize=20)\naxes.set_ylabel(\"Rating Per User\", fontsize=20)\naxes.plot(quantiles)\n\nplt.scatter(x=quantiles.index[::5], y=quantiles.values[::5], c=\"blue\", s=70,\n           label=\"quantiles with 0.05 intervals\")\n\nplt.scatter(x=quantiles.index[::25], y=quantiles.values[::25], c=\"red\", s=70,\n           label=\"quantiles with 0.25 intervals\")\n\nplt.legend(loc='upper left', fontsize=20)\n\nfor x, y in zip(quantiles.index[::25], quantiles.values[::25]):\n    plt.annotate(s='({}, {})'.format(x, y), xy=(x, y), fontweight='bold',\n                fontsize=16, xytext=(x-0.05, y+180))\n    \naxes.tick_params(labelsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quantiles[::5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total number of rating less than 75th percentile: \" +str(sum(user_giving_rate.values <=132)))\nprint(\"Total number of rating more than 75th percentile: \" +str(sum(user_giving_rate.values >132)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Movies Rating Analyst "},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_rating = df.groupby(\"movie_id\")[\"rating\"].count().sort_values(ascending=False)\nmovies_rating.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12, 8))\naxes = fig.add_axes([0.1, 0.1, 1, 1])\nplt.title(\"Rating per Movies\", fontsize=20)\nplt.xlabel(\"Movie\", fontsize=20)\nplt.ylabel(\"Rating Count\", fontsize=20)\nplt.plot(movies_rating.values)\nplt.tick_params(labelsize=15)\naxes.set_xticklabels([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"DayOfWeek\"] = df.date.dt.day_name()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysis Rating on Day of Week"},{"metadata":{"trusted":true},"cell_type":"code","source":"def labels(number):\n    return str(number/10**6) + 'M'\n\nplt.figure(figsize=(12, 8))\nax = sns.countplot(x='rating', data= df)\nax.set_yticklabels([labels(num) for num in ax.get_yticks()])\n\n# plt.tick_params()\nplt.title(\"Distribution of Rating\", fontsize=20)\nplt.xlabel(\"Rating\", fontsize=20)\nplt.ylabel(\"Rating Count(M)\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12, 8))\n\naxes = sns.countplot(x=\"DayOfWeek\", data = df)\naxes.set_title(\"Day of Week VS Number of Rating\", fontsize = 20)\naxes.set_xlabel(\"Day of Week\", fontsize=20)\naxes.set_ylabel(\"Number of Rating\", fontsize=20)\naxes.set_yticklabels([labels(num) for num in ax.get_yticks()])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (12, 8))\n\naxes = sns.boxplot(x=\"DayOfWeek\",y=\"rating\", data=df)\naxes.set_title(\"Day of Week VS Number of Rating\", fontsize=20)\naxes.set_xlabel(\"Day of Week\", fontsize=20)\naxes.set_ylabel(\"Number of Rating\", fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_rating_dayofweek = df.groupby(\"DayOfWeek\")[\"rating\"].mean()\n\nprint(\"Average Rating on Day of Week\")\nprint(avg_rating_dayofweek)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating USER-ITEM sparse matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"startTime = datetime.now()\nprint(\"Creating USER_ITEM sparse matrix for train Data\")\nif os.path.isfile(\"SparseData.npz\"):\n    print(\"Sparse Data is already present in your disk, no need to create further. Loading Sparse Matrix\")\n    SparseData = sparse.load_npz(\"SparseData.npz\")\n    print(\"Shape of Train Sparse matrix = \"+str(SparseData.shape))\n    \nelse:\n    print(\"We are creating sparse data\")\n    SparseData = sparse.csr_matrix((df.rating, (df.user_id, df.movie_id)))\n    print(\"Creation done. Shape of sparse matrix = \"+str(SparseData.shape))\n    print(\"Saving it into disk for furthur usage.\")\n    sparse.save_npz(\"SparseData.npz\", SparseData)\n    print(\"Done\\n\")\n\nprint(datetime.now() - startTime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows, cols = SparseData.shape\nele = SparseData.count_nonzero()\n\nprint(\"Sparse of Data: \"+str((1-(ele/(rows*cols)))*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Global Average Rating"},{"metadata":{"trusted":true},"cell_type":"code","source":"global_avg_rating = SparseData.sum()/SparseData.count_nonzero()\nglobal_avg_rating","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Average Rating"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getAverageRatings(sparseMatrix, if_user):\n    ax = 1 if if_user else 0\n    SumOfRatings = sparseMatrix.sum(axis=ax).A1\n    NoOfRatings = (sparseMatrix!=0).sum(axis=ax).A1\n    \n    rows, cols = sparseMatrix.shape\n    avg_ratings = {i: SumOfRatings[i]/NoOfRatings[i] for i in range(rows if if_user else cols) if NoOfRatings[i]!=0}\n    return avg_ratings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_rating_user = getAverageRatings(SparseData, True)[25] #Average rating of user 25\navg_rating_user","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_rating_movie = getAverageRatings(SparseData, False)[4500]\navg_rating_movie","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Computing User-User Similarity Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"row_index, col_index = SparseData.nonzero()\nrows = np.unique(row_index)\nfor i in rows[:100]:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Top 100 most similar users with first 100 users as above"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getUser_UserSimilarity(sparseMatrix, top = 100):\n    startTimestamp20 = datetime.now()  \n    \n    row_index, col_index = sparseMatrix.nonzero()  \n    rows = np.unique(row_index)\n    similarMatrix = np.zeros(61700).reshape(617,100)   \n    timeTaken = []\n    howManyDone = 0\n    for row in rows[:top]:\n        howManyDone += 1\n        startTimestamp = datetime.now().timestamp() \n        sim = cosine_similarity(sparseMatrix.getrow(row), sparseMatrix).ravel()\n        top100_similar_indices = sim.argsort()[-top:]\n        top100_similar = sim[top100_similar_indices]\n        similarMatrix[row] = top100_similar\n        timeforOne = datetime.now().timestamp() - startTimestamp\n        timeTaken.append(timeforOne)\n        if howManyDone % 20 == 0:\n            print(\"Time elapsed for {} users = {}sec\".format(howManyDone, (datetime.now() - startTimestamp20)))\n    print(\"Average Time taken to compute similarity matrix for 1 user = \"+str(sum(timeTaken)/len(timeTaken))+\"seconds\")\n    \n    fig = plt.figure(figsize = (12,8))\n    plt.plot(timeTaken, label = 'Time Taken For Each User')\n    plt.plot(np.cumsum(timeTaken), label='Cumulative Time')\n    plt.legend(loc='upper left', fontsize = 15)\n    plt.xlabel('Users', fontsize = 20)\n    plt.ylabel('Time(Seconds)', fontsize = 20)\n    plt.tick_params(labelsize = 15)\n    plt.show()\n    \n    return similarMatrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"simMatrix = getUser_UserSimilarity(SparseData, 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Computing Movie-Movie Similarity Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\n\nif not os.path.isfile(\".movie_similarity.npz\"):\n    print(\"Movie-Movie Similarity file does not exist in your disk. Creating Movie-Movie Similarity Matrix...\")\n    \n    movie_similarity = cosine_similarity(SparseData.T, dense_output = False)\n    print(\"Done\")\n    print(\"Dimension of Matrix = {}\".format(movie_similarity.shape))\n    print(\"Storing the Movie Similarity matrix on disk for further usage\")\n    sparse.save_npz(\"movie_similarity.npz\", movie_similarity)\nelse:\n    print(\"File exists in the disk. Loading the file...\")\n    movie_similarity = sparse.load_npz(\"movie_similarity.npz\")\n    print(\"Dimension of Matrix = {}\".format(movie_similarity.shape))\n    \nprint(datetime.now() - start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## checking the top 10 most similary movies."},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_id = np.unique(movie_similarity.nonzero())\n\nsimMovie_dict = dict()\nfor movie in movie_id:\n    sim = np.argsort(-(movie_similarity[movie]).toarray().ravel())[1:100]\n    simMovie_dict[movie] = sim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_title = pd.read_csv('../input/netflix-prize-data/movie_titles.csv', sep=\",\",\n                         header=None, names=[\"movie_id\", \"year_of_release\", \"movie_title\"], index_col=\"movie_id\", encoding=\"iso8859_2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_title.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Similar movies to: Pressure"},{"metadata":{"trusted":true},"cell_type":"code","source":"movieID = 177\nprint(\"Name of the movie: \" +str(movie_title.loc[movieID][1]))\nprint(\"Number of ratings by users for movie {} is {}\".format(movie_title.loc[movieID][1], \n                                                            SparseData[:,movieID].getnnz()))\nprint(\"Number of similar movies to {} is {}\".format(movie_title.loc[movieID][1], movie_similarity[movieID].count_nonzero()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"movieID = 8000\nprint(\"Name of the movie: \" +str(movie_title.loc[movieID][1]))\nprint(\"Number of ratings by users for movie {} is {}\".format(movie_title.loc[movieID][1], \n                                                            SparseData[:,movieID].getnnz()))\nprint(\"Number of similar movies to {} is {}\".format(movie_title.loc[movieID][1], movie_similarity[movieID].count_nonzero()))"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_similar = sorted(movie_similarity[movieID].toarray().ravel(), reverse=True)[1:]\n\nsimilar_100 = all_similar[:101]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 8))\nplt.plot(all_similar, label = \"All Similar\")\nplt.plot(similar_100, label = \"Top 100 Similar Movies\")\nplt.title(\"Similar Movies to Pressure\", fontsize = 25)\nplt.ylabel(\"Cosine Similarity Values\", fontsize = 20)\nplt.legend(fontsize = 20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top 10 Similar Movies to: Pressure"},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_title.loc[simMovie_dict[movieID][:10]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Model"},{"metadata":{},"cell_type":"markdown","source":"take only a smaller dataset of 2,000 top rated movies and 10,000 top users. a new dataframe is shown below.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = pd.DataFrame()\n\ngroup = df.groupby('user_id')['rating'].count()\ntop_user = group.sort_values(ascending=False)[:10000]\n\ngroup = df.groupby('movie_id')['rating'].count()\ntop_movie = group.sort_values(ascending=False)[:2000]\n\nnew_df = df.join(top_user, rsuffix=\"_r\", how=\"inner\", on=\"user_id\")\nnew_df = new_df.join(top_movie, rsuffix=\"_r\", how=\"inner\", on=\"movie_id\")\n                     \nuser_enc = LabelEncoder()\nnew_df['user'] = user_enc.fit_transform(new_df['user_id'].values)\n\nmovie_enc = LabelEncoder()\nnew_df['movie'] = movie_enc.fit_transform(new_df['movie_id'].values)\n\nmovies = new_df['movie'].nunique()\nusers = new_df['user'].nunique()\n\nnew_df\n                                        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.isfile(\"TrainData.pkl\"):\n    new_df.iloc[:int(new_df.shape[0]*0.80)].to_pickle(\"TrainData.pkl\")\n    Train_Data = pd.read_pickle(\"TrainData.pkl\")\n    Train_Data.reset_index(drop = True, inplace = True)\nelse:\n    Train_Data = pd.read_pickle(\"TrainData.pkl\")\n    Train_Data.reset_index(drop = True, inplace = True)\n\nif not os.path.isfile(\"TestData.pkl\"):\n    new_df.iloc[int(new_df.shape[0]*0.80):].to_pickle(\"TestData.pkl\")\n    Test_Data = pd.read_pickle(\"TestData.pkl\")\n    Test_Data.reset_index(drop = True, inplace = True)\nelse:\n    Test_Data = pd.read_pickle(\"TestData.pkl\")\n    Test_Data.reset_index(drop = True, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_Data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sample_sparse_matrix(sparseMatrix, n_users, n_movies):\n    startTime = datetime.now()\n    users, movies, ratings = sparse.find(sparseMatrix)\n    uniq_users = np.unique(users)\n    uniq_movies = np.unique(movies)\n    np.random.seed(15)   #this will give same random number everytime, without replacement\n    userS = np.random.choice(uniq_users, n_users, replace = False)\n    movieS = np.random.choice(uniq_movies, n_movies, replace = False)\n    mask = np.logical_and(np.isin(users, userS), np.isin(movies, movieS))\n    sparse_sample = sparse.csr_matrix((ratings[mask], (users[mask], movies[mask])), \n                                                     shape = (max(userS)+1, max(movieS)+1))\n    print(\"Sparse Matrix creation done. Saving it for later use.\")\n    sparse.save_npz(path, sparse_sample)\n    print(\"Done\")\n    print(\"Shape of Sparse Sampled Matrix = \"+str(sparse_sample.shape))\n    \n    print(datetime.now() - start)\n    return sparse_sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"startTime = datetime.now()\nprint(\"Creating USER_ITEM sparse matrix for train Data\")\nif os.path.isfile(\"TrainUISparseData.npz\"):\n    print(\"Sparse Data is already present in your disk, no need to create further. Loading Sparse Matrix\")\n    TrainUISparseData = sparse.load_npz(\"TrainUISparseData.npz\")\n    print(\"Shape of Train Sparse matrix = \"+str(TrainUISparseData.shape))\n    \nelse:\n    print(\"We are creating sparse data\")\n    TrainUISparseData = sparse.csr_matrix((Train_Data.rating, (Train_Data.user_id, Train_Data.movie_id)))\n    print(\"Creation done. Shape of sparse matrix = \"+str(TrainUISparseData.shape))\n    print(\"Saving it into disk for furthur usage.\")\n    sparse.save_npz(\"TrainUISparseData.npz\", TrainUISparseData)\n    print(\"Done\\n\")\n\nprint(datetime.now() - startTime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"TrainUISparseData_Sample.npz\"\nif not os.path.isfile(path):\n    print(\"Sample sparse matrix is not present in the disk. We are creating it...\")\n    train_sample_sparse = get_sample_sparse_matrix(TrainUISparseData, 4000, 400)\nelse:\n    print(\"File is already present in the disk. Loading the file...\")\n    train_sample_sparse = sparse.load_npz(path)\n    print(\"File loading done.\")\n    print(\"Shape of Train Sample Sparse Matrix = \"+str(train_sample_sparse.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"startTime = datetime.now()\nprint(\"Creating USER_ITEM sparse matrix for test Data\")\nif os.path.isfile(\"TestUISparseData.npz\"):\n    print(\"Sparse Data is already present in your disk, no need to create further. Loading Sparse Matrix\")\n    TestUISparseData = sparse.load_npz(\"TestUISparseData.npz\")\n    print(\"Shape of Test Sparse matrix = \"+str(TestUISparseData.shape))\n    \nelse:\n    print(\"We are creating sparse data\")\n    TestUISparseData = sparse.csr_matrix((Test_Data.rating, (Test_Data.user_id, Test_Data.movie_id)))\n    print(\"Creation done. Shape of sparse matrix = \"+str(TestUISparseData.shape))\n    print(\"Saving it into disk for furthur usage.\")\n    sparse.save_npz(\"TestUISparseData.npz\", TestUISparseData)\n    print(\"Done\\n\")\n\nprint(datetime.now() - startTime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"TestUISparseData_Sample.npz\"\nif not os.path.isfile(path):\n    print(\"Sample sparse matrix is not present in the disk. We are creating it...\")\n    test_sample_sparse = get_sample_sparse_matrix(TestUISparseData, 4000, 400)\nelse:\n    print(\"File is already present in the disk. Loading the file...\")\n    test_sample_sparse = sparse.load_npz(path)\n    print(\"File loading done.\")\n    print(\"Shape of Train Sample Sparse Matrix = \"+str(test_sample_sparse.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"No of ratings in Our Sampled train matrix is : {}\".format(train_sample_sparse.count_nonzero()))\nprint(\"No of ratings in Our Sampled test matrix is : {}\".format(test_sample_sparse.count_nonzero()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reader = Reader(rating_scale=(1,5))\n\ndata = Dataset.load_from_df(new_df[['user_id', 'movie_id', 'rating']], reader)\n\ntrainset = data.build_full_trainset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset = list(zip(new_df[\"user_id\"].values, new_df[\"movie_id\"].values, new_df[\"rating\"].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_table = pd.DataFrame(columns = [\"Model\", \"Train RMSE\", \"Train MAPE\", \"Test RMSE\", \"Test MAPE\"])\nmodel_train_evaluation = dict()\nmodel_test_evaluation = dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_table(model_name, rsme_train, mape_train, rsme_test, mape_test):\n    global error_table\n    error_table = error_table.append(pd.DataFrame([[model_name, rsme_train, mape_train, rsme_test, mape_test]],\n                                                 columns = [\"Model\", \"Train RMSE\", \"Train MAPE\", \"Test RMSE\", \"Test MAPE\"]))\n    error_table.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Utility Functions for Surprise Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"def error_matrics(y_true, y_pred):\n    rsme = np.sqrt(mean_squared_error(y_true, y_pred))\n    mape = np.mean(abs((y_true - y_pred)/y_true))*100\n    return rmse, mape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_ratings(predictions):\n    actual = np.array([pred.r_ui for pred in predictions])\n    predicted = np.array([pred.est for pred in predictions])\n    return actual, predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_error(predictions):\n    actual, predicted = get_ratings(predictions)\n    rmse = np.sqrt(mean_squared_error(actual, predicted)) \n    mape = np.mean(abs((actual - predicted)/actual))*100\n    return rmse, mape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_seed = 15\nrandom.seed(my_seed)\nnp.random.seed(my_seed)\n\ndef run_surprise(algo, trainset, testset, model_name):\n    startTime = datetime.now()\n    \n    train = dict()\n    test = dict()\n    \n    algo.fit(trainset)\n    \n    print(\"-\"*50)\n    print(\"TRAIN DATA\")\n    train_pred = algo.test(trainset.build_testset())\n    \n    train_actual, train_predicted = get_ratings(train_pred)\n    train_rmse, train_mape = get_error(train_pred)\n    print(\"RMSE = {}\".format(train_rmse))\n    print(\"MAPE = {}\".format(train_mape))\n    print(\"-\"*50)\n    train = {\"RMSE\": train_rmse, \"MAPE\": train_mape, \"Prediction\": train_predicted}\n    \n    print(\"TEST DATA\")\n    test_pred = algo.test(testset)\n\n    test_actual, test_predicted = get_ratings(test_pred)\n    test_rmse, test_mape = get_error(test_pred)\n    print(\"RMSE = {}\".format(test_rmse))\n    print(\"MAPE = {}\".format(test_mape))\n    print(\"-\"*50)\n    test = {\"RMSE\": test_rmse, \"MAPE\": test_mape, \"Prediction\": test_predicted}\n    \n    print(\"Time Taken = \"+str(datetime.now() - startTime))\n    \n    make_table(model_name, train_rmse, train_mape, test_rmse, test_mape)\n    \n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = new_df[['user_id', 'movie_id']].values\ny = new_df['rating'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bsl_options = {\"method\":\"sgd\", \"learning_rate\":0.01, \"n_epochs\":25}\n\nalgo = BaselineOnly(bsl_options=bsl_options)\n#You can check the docs of above used functions at:https://surprise.readthedocs.io/en/stable/prediction_algorithms.html#baseline-estimates-configuration\n#at section \"Baselines estimates configuration\".\n\ntrain_result, test_result = run_surprise(algo, trainset, testset, \"BaselineOnly\")\n\nmodel_train_evaluation[\"BaselineOnly\"] = train_result\nmodel_test_evaluation[\"BaselineOnly\"] = test_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"sim_options = {'name':'pearson_baseline', 'user_based':True, 'min_support':2, 'shrinkage':60}\n\nbsl_options = {'method': 'sgd'} \n\nalgo = KNNBaseline(k = 10, sim_options = sim_options, bsl_options=bsl_options)\n\ntrain_result, test_result = run_surprise(algo, trainset, testset, \"KNNBaseline_User\")\n\nmodel_train_evaluation[\"KNNBaseline_User\"] = train_result\nmodel_test_evaluation[\"KNNBaseline_User\"] = test_result"},{"metadata":{"trusted":true},"cell_type":"code","source":"algo = SVD(n_factors = 5, biased=True, verbose=True)\n\ntrain_result, test_result = run_surprise(algo, trainset, testset, \"SVD\")\n\nmodel_train_evaluation[\"SVD\"] = train_result\nmodel_test_evaluation[\"SVD\"] = test_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algo = SVDpp(n_factors = 10, lr_all = 0.006, verbose=True)\n\ntrain_result, test_result = run_surprise(algo, trainset, testset, \"SVDpp\")\n\nmodel_train_evaluation[\"SVDpp\"] = train_result\nmodel_test_evaluation[\"SVDpp\"] = test_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sim_options = {'name':'pearson_baseline', 'user_based':True, 'min_support':2, 'shrinkage':10}\n\nbsl_options = {'method': 'sgd'} \n\nalgo = KNNBaseline(k = 1, sim_options = sim_options, bsl_options=bsl_options)\n\ntrain_result, test_result = run_surprise(algo, trainset, testset, \"KNNBaseline_Item\")\n\nmodel_train_evaluation[\"KNNBaseline_Item\"] = train_result\nmodel_test_evaluation[\"KNNBaseline_Item\"] = test_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"sim_options = {'name':'pearson_baseline', 'user_based':True, 'min_support':2, 'shrinkage':10}\n\nbsl_options = {'method': 'sgd'} \n\nalgo = KNNBaseline(k = 1, sim_options = sim_options, bsl_options=bsl_options)\n\ntrain_result, test_result = run_surprise(algo, trainset, testset, \"KNNBaseline_Item\")\n\nmodel_train_evaluation[\"KNNBaseline_Item\"] = train_result\nmodel_test_evaluation[\"KNNBaseline_Item\"] = test_result"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}